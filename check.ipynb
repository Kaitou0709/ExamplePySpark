{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyspark\n",
      "  Using cached pyspark-3.3.2.tar.gz (281.4 MB)\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: py4j==0.10.9.5 in c:\\users\\admin\\appdata\\local\\packages\\pythonsoftwarefoundation.python.3.10_qbz5n2kfra8p0\\localcache\\local-packages\\python310\\site-packages (from pyspark) (0.10.9.5)\n",
      "Installing collected packages: pyspark\n",
      "  Running setup.py install for pyspark: started\n",
      "  Running setup.py install for pyspark: finished with status 'error'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  DEPRECATION: pyspark is being installed using the legacy 'setup.py install' method, because it does not have a 'pyproject.toml' and the 'wheel' package is not installed. pip 23.1 will enforce this behaviour change. A possible replacement is to enable the '--use-pep517' option. Discussion can be found at https://github.com/pypa/pip/issues/8559\n",
      "  error: subprocess-exited-with-error\n",
      "  \n",
      "  × Running setup.py install for pyspark did not run successfully.\n",
      "  │ exit code: 1\n",
      "  ╰─> [1126 lines of output]\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\dist.py:771: UserWarning: Usage of dash-separated 'description-file' will not be supported in future versions. Please use the underscore name 'description_file' instead\n",
      "        warnings.warn(\n",
      "      running install\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\install.py:34: SetuptoolsDeprecationWarning: setup.py install is deprecated. Use build and pip and other standards-based tools.\n",
      "        warnings.warn(\n",
      "      running build\n",
      "      running build_py\n",
      "      creating build\n",
      "      creating build\\lib\n",
      "      creating build\\lib\\pyspark\n",
      "      copying pyspark\\accumulators.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\broadcast.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\conf.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\context.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\daemon.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\files.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\find_spark_home.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\install.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\instrumentation_utils.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\java_gateway.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\join.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\profiler.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\rdd.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\rddsampler.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\resultiterable.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\serializers.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\shell.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\shuffle.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\statcounter.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\status.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\storagelevel.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\taskcontext.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\traceback_utils.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\util.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\version.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\worker.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\_globals.py -> build\\lib\\pyspark\n",
      "      copying pyspark\\__init__.py -> build\\lib\\pyspark\n",
      "      creating build\\lib\\pyspark\\cloudpickle\n",
      "      copying pyspark\\cloudpickle\\cloudpickle.py -> build\\lib\\pyspark\\cloudpickle\n",
      "      copying pyspark\\cloudpickle\\cloudpickle_fast.py -> build\\lib\\pyspark\\cloudpickle\n",
      "      copying pyspark\\cloudpickle\\compat.py -> build\\lib\\pyspark\\cloudpickle\n",
      "      copying pyspark\\cloudpickle\\__init__.py -> build\\lib\\pyspark\\cloudpickle\n",
      "      creating build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\classification.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\clustering.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\common.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\evaluation.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\feature.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\fpm.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\random.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\recommendation.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\regression.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\tree.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\util.py -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\__init__.py -> build\\lib\\pyspark\\mllib\n",
      "      creating build\\lib\\pyspark\\mllib\\linalg\n",
      "      copying pyspark\\mllib\\linalg\\distributed.py -> build\\lib\\pyspark\\mllib\\linalg\n",
      "      copying pyspark\\mllib\\linalg\\__init__.py -> build\\lib\\pyspark\\mllib\\linalg\n",
      "      creating build\\lib\\pyspark\\mllib\\stat\n",
      "      copying pyspark\\mllib\\stat\\distribution.py -> build\\lib\\pyspark\\mllib\\stat\n",
      "      copying pyspark\\mllib\\stat\\KernelDensity.py -> build\\lib\\pyspark\\mllib\\stat\n",
      "      copying pyspark\\mllib\\stat\\test.py -> build\\lib\\pyspark\\mllib\\stat\n",
      "      copying pyspark\\mllib\\stat\\_statistics.py -> build\\lib\\pyspark\\mllib\\stat\n",
      "      copying pyspark\\mllib\\stat\\__init__.py -> build\\lib\\pyspark\\mllib\\stat\n",
      "      creating build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\base.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\classification.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\clustering.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\common.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\evaluation.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\feature.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\fpm.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\functions.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\image.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\pipeline.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\recommendation.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\regression.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\stat.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\tree.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\tuning.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\util.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\wrapper.py -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\ml\\__init__.py -> build\\lib\\pyspark\\ml\n",
      "      creating build\\lib\\pyspark\\ml\\linalg\n",
      "      copying pyspark\\ml\\linalg\\__init__.py -> build\\lib\\pyspark\\ml\\linalg\n",
      "      creating build\\lib\\pyspark\\ml\\param\n",
      "      copying pyspark\\ml\\param\\shared.py -> build\\lib\\pyspark\\ml\\param\n",
      "      copying pyspark\\ml\\param\\_shared_params_code_gen.py -> build\\lib\\pyspark\\ml\\param\n",
      "      copying pyspark\\ml\\param\\__init__.py -> build\\lib\\pyspark\\ml\\param\n",
      "      creating build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\catalog.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\column.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\conf.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\context.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\dataframe.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\functions.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\group.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\observation.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\readwriter.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\session.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\sql_formatter.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\streaming.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\types.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\udf.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\utils.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\window.py -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\__init__.py -> build\\lib\\pyspark\\sql\n",
      "      creating build\\lib\\pyspark\\sql\\avro\n",
      "      copying pyspark\\sql\\avro\\functions.py -> build\\lib\\pyspark\\sql\\avro\n",
      "      copying pyspark\\sql\\avro\\__init__.py -> build\\lib\\pyspark\\sql\\avro\n",
      "      creating build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\conversion.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\functions.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\group_ops.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\map_ops.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\serializers.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\typehints.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\types.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\utils.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      copying pyspark\\sql\\pandas\\__init__.py -> build\\lib\\pyspark\\sql\\pandas\n",
      "      creating build\\lib\\pyspark\\streaming\n",
      "      copying pyspark\\streaming\\context.py -> build\\lib\\pyspark\\streaming\n",
      "      copying pyspark\\streaming\\dstream.py -> build\\lib\\pyspark\\streaming\n",
      "      copying pyspark\\streaming\\kinesis.py -> build\\lib\\pyspark\\streaming\n",
      "      copying pyspark\\streaming\\listener.py -> build\\lib\\pyspark\\streaming\n",
      "      copying pyspark\\streaming\\util.py -> build\\lib\\pyspark\\streaming\n",
      "      copying pyspark\\streaming\\__init__.py -> build\\lib\\pyspark\\streaming\n",
      "      creating build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\accessors.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\base.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\categorical.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\config.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\datetimes.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\exceptions.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\extensions.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\frame.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\generic.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\groupby.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\indexing.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\internal.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\ml.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\mlflow.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\namespace.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\numpy_compat.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\series.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\sql_formatter.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\sql_processor.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\strings.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\utils.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\window.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\_typing.py -> build\\lib\\pyspark\\pandas\n",
      "      copying pyspark\\pandas\\__init__.py -> build\\lib\\pyspark\\pandas\n",
      "      creating build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\base.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\binary_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\boolean_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\categorical_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\complex_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\datetime_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\date_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\null_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\num_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\string_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\timedelta_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\udt_ops.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      copying pyspark\\pandas\\data_type_ops\\__init__.py -> build\\lib\\pyspark\\pandas\\data_type_ops\n",
      "      creating build\\lib\\pyspark\\pandas\\indexes\n",
      "      copying pyspark\\pandas\\indexes\\base.py -> build\\lib\\pyspark\\pandas\\indexes\n",
      "      copying pyspark\\pandas\\indexes\\category.py -> build\\lib\\pyspark\\pandas\\indexes\n",
      "      copying pyspark\\pandas\\indexes\\datetimes.py -> build\\lib\\pyspark\\pandas\\indexes\n",
      "      copying pyspark\\pandas\\indexes\\multi.py -> build\\lib\\pyspark\\pandas\\indexes\n",
      "      copying pyspark\\pandas\\indexes\\numeric.py -> build\\lib\\pyspark\\pandas\\indexes\n",
      "      copying pyspark\\pandas\\indexes\\timedelta.py -> build\\lib\\pyspark\\pandas\\indexes\n",
      "      copying pyspark\\pandas\\indexes\\__init__.py -> build\\lib\\pyspark\\pandas\\indexes\n",
      "      creating build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\common.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\frame.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\general_functions.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\groupby.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\indexes.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\series.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\window.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      copying pyspark\\pandas\\missing\\__init__.py -> build\\lib\\pyspark\\pandas\\missing\n",
      "      creating build\\lib\\pyspark\\pandas\\plot\n",
      "      copying pyspark\\pandas\\plot\\core.py -> build\\lib\\pyspark\\pandas\\plot\n",
      "      copying pyspark\\pandas\\plot\\matplotlib.py -> build\\lib\\pyspark\\pandas\\plot\n",
      "      copying pyspark\\pandas\\plot\\plotly.py -> build\\lib\\pyspark\\pandas\\plot\n",
      "      copying pyspark\\pandas\\plot\\__init__.py -> build\\lib\\pyspark\\pandas\\plot\n",
      "      creating build\\lib\\pyspark\\pandas\\spark\n",
      "      copying pyspark\\pandas\\spark\\accessors.py -> build\\lib\\pyspark\\pandas\\spark\n",
      "      copying pyspark\\pandas\\spark\\functions.py -> build\\lib\\pyspark\\pandas\\spark\n",
      "      copying pyspark\\pandas\\spark\\utils.py -> build\\lib\\pyspark\\pandas\\spark\n",
      "      copying pyspark\\pandas\\spark\\__init__.py -> build\\lib\\pyspark\\pandas\\spark\n",
      "      creating build\\lib\\pyspark\\pandas\\typedef\n",
      "      copying pyspark\\pandas\\typedef\\typehints.py -> build\\lib\\pyspark\\pandas\\typedef\n",
      "      copying pyspark\\pandas\\typedef\\__init__.py -> build\\lib\\pyspark\\pandas\\typedef\n",
      "      creating build\\lib\\pyspark\\pandas\\usage_logging\n",
      "      copying pyspark\\pandas\\usage_logging\\usage_logger.py -> build\\lib\\pyspark\\pandas\\usage_logging\n",
      "      copying pyspark\\pandas\\usage_logging\\__init__.py -> build\\lib\\pyspark\\pandas\\usage_logging\n",
      "      creating build\\lib\\pyspark\\python\n",
      "      creating build\\lib\\pyspark\\python\\pyspark\n",
      "      copying pyspark\\python\\pyspark\\shell.py -> build\\lib\\pyspark\\python\\pyspark\n",
      "      creating build\\lib\\pyspark\\resource\n",
      "      copying pyspark\\resource\\information.py -> build\\lib\\pyspark\\resource\n",
      "      copying pyspark\\resource\\profile.py -> build\\lib\\pyspark\\resource\n",
      "      copying pyspark\\resource\\requests.py -> build\\lib\\pyspark\\resource\n",
      "      copying pyspark\\resource\\__init__.py -> build\\lib\\pyspark\\resource\n",
      "      creating build\\lib\\pyspark\\examples\n",
      "      creating build\\lib\\pyspark\\examples\\src\n",
      "      creating build\\lib\\pyspark\\examples\\src\\main\n",
      "      creating build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\als.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\avro_inputformat.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\kmeans.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\logistic_regression.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\pagerank.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\parquet_inputformat.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\pi.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\sort.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\status_api_demo.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\transitive_closure.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      copying deps\\examples\\__init__.py -> build\\lib\\pyspark\\examples\\src\\main\\python\n",
      "      running egg_info\n",
      "      writing pyspark.egg-info\\PKG-INFO\n",
      "      writing dependency_links to pyspark.egg-info\\dependency_links.txt\n",
      "      writing requirements to pyspark.egg-info\\requires.txt\n",
      "      writing top-level names to pyspark.egg-info\\top_level.txt\n",
      "      reading manifest file 'pyspark.egg-info\\SOURCES.txt'\n",
      "      reading manifest template 'MANIFEST.in'\n",
      "      warning: no previously-included files matching '*.py[cod]' found anywhere in distribution\n",
      "      warning: no previously-included files matching '__pycache__' found anywhere in distribution\n",
      "      warning: no previously-included files matching '.DS_Store' found anywhere in distribution\n",
      "      writing manifest file 'pyspark.egg-info\\SOURCES.txt'\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.data.graphx' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.data.graphx' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.data.graphx' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.data.graphx' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.data.mllib' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.data.mllib' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.data.mllib' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.data.mllib' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.data.mllib.als' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.data.mllib.als' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.data.mllib.als' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.data.mllib.als' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.data.mllib.images' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.data.mllib.images' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.data.mllib.images' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.data.mllib.images' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.data.mllib.images.origin' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.data.mllib.images.origin' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.data.mllib.images.origin' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.data.mllib.images.origin' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.data.mllib.images.origin.kittens' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.data.mllib.images.origin.kittens' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.data.mllib.images.origin.kittens' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.data.mllib.images.origin.kittens' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.data.streaming' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.data.streaming' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.data.streaming' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.data.streaming' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.examples.src.main.python.ml' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.examples.src.main.python.ml' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.examples.src.main.python.ml' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.examples.src.main.python.ml' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.examples.src.main.python.mllib' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.examples.src.main.python.mllib' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.examples.src.main.python.mllib' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.examples.src.main.python.mllib' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.examples.src.main.python.sql' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.examples.src.main.python.sql' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.examples.src.main.python.sql' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.examples.src.main.python.sql' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.examples.src.main.python.sql.streaming' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.examples.src.main.python.sql.streaming' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.examples.src.main.python.sql.streaming' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.examples.src.main.python.sql.streaming' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.examples.src.main.python.streaming' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.examples.src.main.python.streaming' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.examples.src.main.python.streaming' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.examples.src.main.python.streaming' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.sql.pandas._typing' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.sql.pandas._typing' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.sql.pandas._typing' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.sql.pandas._typing' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      C:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_3.10.2800.0_x64__qbz5n2kfra8p0\\lib\\site-packages\\setuptools\\command\\build_py.py:202: SetuptoolsDeprecationWarning:     Installing 'pyspark.sql.pandas._typing.protocols' as data is deprecated, please list it in `packages`.\n",
      "          !!\n",
      "      \n",
      "      \n",
      "          ############################\n",
      "          # Package would be ignored #\n",
      "          ############################\n",
      "          Python recognizes 'pyspark.sql.pandas._typing.protocols' as an importable package,\n",
      "          but it is not listed in the `packages` configuration of setuptools.\n",
      "      \n",
      "          'pyspark.sql.pandas._typing.protocols' has been automatically added to the distribution only\n",
      "          because it may contain data files, but this behavior is likely to change\n",
      "          in future versions of setuptools (and therefore is considered deprecated).\n",
      "      \n",
      "          Please make sure that 'pyspark.sql.pandas._typing.protocols' is included as a package by using\n",
      "          the `packages` configuration field or the proper discovery methods\n",
      "          (for example by using `find_namespace_packages(...)`/`find_namespace:`\n",
      "          instead of `find_packages(...)`/`find:`).\n",
      "      \n",
      "          You can read more about \"package discovery\" and \"data files\" on setuptools\n",
      "          documentation page.\n",
      "      \n",
      "      \n",
      "      !!\n",
      "      \n",
      "        check.warn(importable)\n",
      "      copying pyspark\\_typing.pyi -> build\\lib\\pyspark\n",
      "      copying pyspark\\py.typed -> build\\lib\\pyspark\n",
      "      copying pyspark\\mllib\\_typing.pyi -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\random.pyi -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\mllib\\recommendation.pyi -> build\\lib\\pyspark\\mllib\n",
      "      copying pyspark\\ml\\_typing.pyi -> build\\lib\\pyspark\\ml\n",
      "      copying pyspark\\sql\\_typing.pyi -> build\\lib\\pyspark\\sql\n",
      "      copying pyspark\\sql\\pandas\\functions.pyi -> build\\lib\\pyspark\\sql\\pandas\n",
      "      creating build\\lib\\pyspark\\sql\\pandas\\_typing\n",
      "      copying pyspark\\sql\\pandas\\_typing\\__init__.pyi -> build\\lib\\pyspark\\sql\\pandas\\_typing\n",
      "      creating build\\lib\\pyspark\\sql\\pandas\\_typing\\protocols\n",
      "      copying pyspark\\sql\\pandas\\_typing\\protocols\\__init__.pyi -> build\\lib\\pyspark\\sql\\pandas\\_typing\\protocols\n",
      "      copying pyspark\\sql\\pandas\\_typing\\protocols\\frame.pyi -> build\\lib\\pyspark\\sql\\pandas\\_typing\\protocols\n",
      "      copying pyspark\\sql\\pandas\\_typing\\protocols\\series.pyi -> build\\lib\\pyspark\\sql\\pandas\\_typing\\protocols\n",
      "      creating build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\beeline -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\beeline.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\docker-image-tool.sh -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\find-spark-home -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\find-spark-home.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\load-spark-env.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\load-spark-env.sh -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\pyspark -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\pyspark.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\pyspark2.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\run-example -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\run-example.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-class -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-class.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-class2.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-shell -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-shell.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-shell2.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-sql -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-sql.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-sql2.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-submit -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-submit.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\spark-submit2.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\sparkR -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\sparkR.cmd -> build\\lib\\pyspark\\bin\n",
      "      copying deps\\bin\\sparkR2.cmd -> build\\lib\\pyspark\\bin\n",
      "      creating build\\lib\\pyspark\\sbin\n",
      "      copying deps\\sbin\\spark-config.sh -> build\\lib\\pyspark\\sbin\n",
      "      copying deps\\sbin\\spark-daemon.sh -> build\\lib\\pyspark\\sbin\n",
      "      copying deps\\sbin\\start-history-server.sh -> build\\lib\\pyspark\\sbin\n",
      "      copying deps\\sbin\\stop-history-server.sh -> build\\lib\\pyspark\\sbin\n",
      "      creating build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\HikariCP-2.5.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\JLargeArrays-1.5.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\JTransforms-3.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\RoaringBitmap-0.9.25.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\ST4-4.0.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\activation-1.1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\aircompressor-0.21.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\algebra_2.12-2.0.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\annotations-17.0.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\antlr-runtime-3.5.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\antlr4-runtime-4.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\aopalliance-repackaged-2.6.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\arpack-2.2.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\arpack_combined_all-0.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\arrow-format-7.0.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\arrow-memory-core-7.0.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\arrow-memory-netty-7.0.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\arrow-vector-7.0.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\audience-annotations-0.5.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\automaton-1.11-8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\avro-1.11.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\avro-ipc-1.11.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\avro-mapred-1.11.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\blas-2.2.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\bonecp-0.8.0.RELEASE.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\breeze-macros_2.12-1.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\breeze_2.12-1.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\cats-kernel_2.12-2.1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\chill-java-0.10.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\chill_2.12-0.10.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-cli-1.5.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-codec-1.15.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-collections-3.2.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-collections4-4.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-compiler-3.0.16.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-compress-1.21.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-crypto-1.1.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-dbcp-1.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-io-2.11.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-lang-2.6.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-lang3-3.12.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-logging-1.1.3.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-math3-3.6.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-pool-1.5.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\commons-text-1.10.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\compress-lzf-1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\core-1.1.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\curator-client-2.13.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\curator-framework-2.13.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\curator-recipes-2.13.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\datanucleus-api-jdo-4.2.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\datanucleus-core-4.1.17.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\datanucleus-rdbms-4.1.19.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\derby-10.14.2.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\dropwizard-metrics-hadoop-metrics2-reporter-0.1.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\flatbuffers-java-1.12.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\generex-1.0.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\gson-2.2.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\guava-14.0.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hadoop-client-api-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hadoop-client-runtime-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hadoop-shaded-guava-1.1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hadoop-yarn-server-web-proxy-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-beeline-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-cli-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-common-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-exec-2.3.9-core.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-jdbc-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-llap-common-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-metastore-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-serde-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-service-rpc-3.1.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-shims-0.23-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-shims-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-shims-common-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-shims-scheduler-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-storage-api-2.7.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hive-vector-code-gen-2.3.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hk2-api-2.6.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hk2-locator-2.6.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\hk2-utils-2.6.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\httpclient-4.5.13.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\httpcore-4.4.14.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\istack-commons-runtime-3.0.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\ivy-2.5.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-annotations-2.13.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-core-2.13.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-core-asl-1.9.13.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-databind-2.13.4.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-dataformat-yaml-2.13.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-datatype-jsr310-2.13.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-mapper-asl-1.9.13.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jackson-module-scala_2.12-2.13.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jakarta.annotation-api-1.3.5.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jakarta.inject-2.6.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jakarta.servlet-api-4.0.3.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jakarta.validation-api-2.0.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jakarta.ws.rs-api-2.1.6.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jakarta.xml.bind-api-2.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\janino-3.0.16.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\javassist-3.25.0-GA.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\javax.jdo-3.2.0-m3.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\javolution-5.5.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jaxb-runtime-2.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jcl-over-slf4j-1.7.32.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jdo-api-3.0.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jersey-client-2.36.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jersey-common-2.36.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jersey-container-servlet-2.36.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jersey-container-servlet-core-2.36.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jersey-hk2-2.36.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jersey-server-2.36.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jline-2.14.6.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\joda-time-2.10.13.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jodd-core-3.5.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jpam-1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\json-1.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\json4s-ast_2.12-3.7.0-M11.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\json4s-core_2.12-3.7.0-M11.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\json4s-jackson_2.12-3.7.0-M11.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\json4s-scalap_2.12-3.7.0-M11.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jsr305-3.0.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jta-1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\jul-to-slf4j-1.7.32.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kryo-shaded-4.0.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-client-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-admissionregistration-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-apiextensions-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-apps-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-autoscaling-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-batch-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-certificates-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-common-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-coordination-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-core-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-discovery-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-events-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-extensions-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-flowcontrol-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-metrics-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-networking-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-node-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-policy-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-rbac-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-scheduling-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\kubernetes-model-storageclass-5.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\lapack-2.2.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\leveldbjni-all-1.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\libfb303-0.9.3.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\libthrift-0.12.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\log4j-1.2-api-2.17.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\log4j-api-2.17.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\log4j-core-2.17.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\log4j-slf4j-impl-2.17.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\logging-interceptor-3.12.12.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\lz4-java-1.8.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\mesos-1.4.3-shaded-protobuf.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\metrics-core-4.2.7.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\metrics-graphite-4.2.7.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\metrics-jmx-4.2.7.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\metrics-json-4.2.7.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\metrics-jvm-4.2.7.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\minlog-1.3.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-all-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-buffer-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-codec-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-common-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-handler-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-resolver-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-tcnative-classes-2.0.48.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-classes-epoll-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-classes-kqueue-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-native-epoll-4.1.74.Final-linux-aarch_64.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-native-epoll-4.1.74.Final-linux-x86_64.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-native-kqueue-4.1.74.Final-osx-aarch_64.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-native-kqueue-4.1.74.Final-osx-x86_64.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\netty-transport-native-unix-common-4.1.74.Final.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\objenesis-3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\okhttp-3.12.12.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\okio-1.14.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\opencsv-2.3.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\orc-core-1.7.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\orc-mapreduce-1.7.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\orc-shims-1.7.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\oro-2.0.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\osgi-resource-locator-1.0.3.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\paranamer-2.8.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\parquet-column-1.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\parquet-common-1.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\parquet-encoding-1.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\parquet-format-structures-1.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\parquet-hadoop-1.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\parquet-jackson-1.12.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\pickle-1.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\protobuf-java-2.5.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\py4j-0.10.9.5.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\rocksdbjni-6.20.3.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\scala-collection-compat_2.12-2.1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\scala-compiler-2.12.15.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\scala-library-2.12.15.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\scala-parser-combinators_2.12-1.1.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\scala-reflect-2.12.15.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\scala-xml_2.12-1.2.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\shapeless_2.12-2.3.7.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\shims-0.9.25.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\slf4j-api-1.7.32.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\snakeyaml-1.31.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\snappy-java-1.1.8.4.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-catalyst_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-core_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-graphx_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-hive-thriftserver_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-hive_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-kubernetes_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-kvstore_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-launcher_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-mesos_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-mllib-local_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-mllib_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-network-common_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-network-shuffle_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-repl_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-sketch_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-sql_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-streaming_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-tags_2.12-3.3.2-tests.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-tags_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-unsafe_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spark-yarn_2.12-3.3.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spire-macros_2.12-0.17.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spire-platform_2.12-0.17.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spire-util_2.12-0.17.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\spire_2.12-0.17.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\stax-api-1.0.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\stream-2.9.6.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\super-csv-2.2.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\threeten-extra-1.5.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\tink-1.6.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\transaction-api-1.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\univocity-parsers-2.9.1.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\velocity-1.5.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\xbean-asm9-shaded-4.20.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\xz-1.9.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\zjsonpatch-0.3.0.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\zookeeper-3.6.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\zookeeper-jute-3.6.2.jar -> build\\lib\\pyspark\\jars\n",
      "      copying deps\\jars\\zstd-jni-1.5.2-1.jar -> build\\lib\\pyspark\\jars\n",
      "      creating build\\lib\\pyspark\\python\\lib\n",
      "      copying lib\\py4j-0.10.9.5-src.zip -> build\\lib\\pyspark\\python\\lib\n",
      "      copying lib\\pyspark.zip -> build\\lib\\pyspark\\python\\lib\n",
      "      creating build\\lib\\pyspark\\data\n",
      "      creating build\\lib\\pyspark\\data\\graphx\n",
      "      copying deps\\data\\graphx\\followers.txt -> build\\lib\\pyspark\\data\\graphx\n",
      "      copying deps\\data\\graphx\\users.txt -> build\\lib\\pyspark\\data\\graphx\n",
      "      creating build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\gmm_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\kmeans_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\pagerank_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\pic_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_binary_classification_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_fpgrowth.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_isotonic_regression_libsvm_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_kmeans_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_lda_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_lda_libsvm_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_libsvm_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_linear_regression_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_movielens_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_multiclass_classification_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\sample_svm_data.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      copying deps\\data\\mllib\\streaming_kmeans_data_test.txt -> build\\lib\\pyspark\\data\\mllib\n",
      "      creating build\\lib\\pyspark\\data\\mllib\\als\n",
      "      copying deps\\data\\mllib\\als\\sample_movielens_ratings.txt -> build\\lib\\pyspark\\data\\mllib\\als\n",
      "      copying deps\\data\\mllib\\als\\test.data -> build\\lib\\pyspark\\data\\mllib\\als\n",
      "      creating build\\lib\\pyspark\\data\\mllib\\images\n",
      "      copying deps\\data\\mllib\\images\\license.txt -> build\\lib\\pyspark\\data\\mllib\\images\n",
      "      creating build\\lib\\pyspark\\data\\mllib\\images\\origin\n",
      "      copying deps\\data\\mllib\\images\\origin\\license.txt -> build\\lib\\pyspark\\data\\mllib\\images\\origin\n",
      "      creating build\\lib\\pyspark\\data\\mllib\\images\\origin\\kittens\n",
      "      copying deps\\data\\mllib\\images\\origin\\kittens\\not-image.txt -> build\\lib\\pyspark\\data\\mllib\\images\\origin\\kittens\n",
      "      creating build\\lib\\pyspark\\data\\mllib\\ridge-data\n",
      "      copying deps\\data\\mllib\\ridge-data\\lpsa.data -> build\\lib\\pyspark\\data\\mllib\\ridge-data\n",
      "      creating build\\lib\\pyspark\\data\\streaming\n",
      "      copying deps\\data\\streaming\\AFINN-111.txt -> build\\lib\\pyspark\\data\\streaming\n",
      "      creating build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-AnchorJS.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-CC0.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-bootstrap.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-cloudpickle.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-copybutton.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-d3.min.js.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-dagre-d3.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-datatables.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-graphlib-dot.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-jdom.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-join.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-jquery.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-json-formatter.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-matchMedia-polyfill.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-modernizr.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-mustache.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-py4j.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-respond.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-sbt-launch-lib.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-sorttable.js.txt -> build\\lib\\pyspark\\licenses\n",
      "      copying deps\\licenses\\LICENSE-vis-timeline.txt -> build\\lib\\pyspark\\licenses\n",
      "      creating build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\aft_survival_regression.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\als_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\binarizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\bisecting_k_means_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\bucketed_random_projection_lsh_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\bucketizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\chi_square_test_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\chisq_selector_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\correlation_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\count_vectorizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\cross_validator.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\dataframe_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\dct_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\decision_tree_classification_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\decision_tree_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\elementwise_product_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\estimator_transformer_param_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\feature_hasher_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\fm_classifier_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\fm_regressor_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\fpgrowth_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\gaussian_mixture_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\generalized_linear_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\gradient_boosted_tree_classifier_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\gradient_boosted_tree_regressor_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\imputer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\index_to_string_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\interaction_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\isotonic_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\kmeans_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\lda_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\linear_regression_with_elastic_net.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\linearsvc.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\logistic_regression_summary_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\logistic_regression_with_elastic_net.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\max_abs_scaler_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\min_hash_lsh_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\min_max_scaler_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\multiclass_logistic_regression_with_elastic_net.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\multilayer_perceptron_classification.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\n_gram_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\naive_bayes_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\normalizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\one_vs_rest_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\onehot_encoder_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\pca_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\pipeline_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\polynomial_expansion_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\power_iteration_clustering_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\prefixspan_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\quantile_discretizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\random_forest_classifier_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\random_forest_regressor_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\rformula_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\robust_scaler_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\sql_transformer.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\standard_scaler_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\stopwords_remover_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\string_indexer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\summarizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\tf_idf_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\tokenizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\train_validation_split.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\univariate_feature_selector_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\variance_threshold_selector_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\vector_assembler_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\vector_indexer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\vector_size_hint_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\vector_slicer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      copying deps\\examples\\ml\\word2vec_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\ml\n",
      "      creating build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\__init__.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\binary_classification_metrics_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\bisecting_k_means_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\correlations.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\correlations_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\decision_tree_classification_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\decision_tree_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\elementwise_product_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\fpgrowth_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\gaussian_mixture_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\gaussian_mixture_model.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\gradient_boosting_classification_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\gradient_boosting_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\hypothesis_testing_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\hypothesis_testing_kolmogorov_smirnov_test_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\isotonic_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\k_means_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\kernel_density_estimation_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\kmeans.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\latent_dirichlet_allocation_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\linear_regression_with_sgd_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\logistic_regression.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\logistic_regression_with_lbfgs_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\multi_class_metrics_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\multi_label_metrics_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\naive_bayes_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\normalizer_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\pca_rowmatrix_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\power_iteration_clustering_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\random_forest_classification_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\random_forest_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\random_rdd_generation.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\ranking_metrics_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\recommendation_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\regression_metrics_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\sampled_rdds.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\standard_scaler_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\stratified_sampling_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\streaming_k_means_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\streaming_linear_regression_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\summary_statistics_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\svd_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\svm_with_sgd_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\tf_idf_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\word2vec.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      copying deps\\examples\\mllib\\word2vec_example.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\mllib\n",
      "      creating build\\lib\\pyspark\\examples\\src\\main\\python\\sql\n",
      "      copying deps\\examples\\sql\\__init__.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\n",
      "      copying deps\\examples\\sql\\arrow.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\n",
      "      copying deps\\examples\\sql\\basic.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\n",
      "      copying deps\\examples\\sql\\datasource.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\n",
      "      copying deps\\examples\\sql\\hive.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\n",
      "      creating build\\lib\\pyspark\\examples\\src\\main\\python\\sql\\streaming\n",
      "      copying deps\\examples\\sql\\streaming\\structured_kafka_wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\\streaming\n",
      "      copying deps\\examples\\sql\\streaming\\structured_network_wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\\streaming\n",
      "      copying deps\\examples\\sql\\streaming\\structured_network_wordcount_windowed.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\\streaming\n",
      "      copying deps\\examples\\sql\\streaming\\structured_sessionization.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\sql\\streaming\n",
      "      creating build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\__init__.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\hdfs_wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\network_wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\network_wordjoinsentiments.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\queue_stream.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\recoverable_network_wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\sql_network_wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      copying deps\\examples\\streaming\\stateful_network_wordcount.py -> build\\lib\\pyspark\\examples\\src\\main\\python\\streaming\n",
      "      running build_scripts\n",
      "      creating build\\scripts-3.10\n",
      "      copying deps\\bin\\beeline -> build\\scripts-3.10\n",
      "      copying deps\\bin\\beeline.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\docker-image-tool.sh -> build\\scripts-3.10\n",
      "      copying deps\\bin\\find-spark-home -> build\\scripts-3.10\n",
      "      copying deps\\bin\\find-spark-home.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\load-spark-env.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\load-spark-env.sh -> build\\scripts-3.10\n",
      "      copying deps\\bin\\pyspark -> build\\scripts-3.10\n",
      "      copying deps\\bin\\pyspark.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\pyspark2.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\run-example -> build\\scripts-3.10\n",
      "      copying deps\\bin\\run-example.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-class -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-class.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-class2.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-shell -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-shell.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-shell2.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-sql -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-sql.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-sql2.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-submit -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-submit.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\spark-submit2.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\sparkR -> build\\scripts-3.10\n",
      "      copying deps\\bin\\sparkR.cmd -> build\\scripts-3.10\n",
      "      copying deps\\bin\\sparkR2.cmd -> build\\scripts-3.10\n",
      "      copying and adjusting pyspark\\find_spark_home.py -> build\\scripts-3.10\n",
      "      running install_lib\n",
      "      copying build\\lib\\pyspark\\python\\pyspark\\shell.py -> C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\python\\pyspark\n",
      "      byte-compiling C:\\Users\\ADMIN\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python310\\site-packages\\pyspark\\examples\\src\\main\\python\\ml\\multiclass_logistic_regression_with_elastic_net.py to multiclass_logistic_regression_with_elastic_net.cpython-310.pyc\n",
      "      error: [Errno 2] No such file or directory: 'C:\\\\Users\\\\ADMIN\\\\AppData\\\\Local\\\\Packages\\\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\\\LocalCache\\\\local-packages\\\\Python310\\\\site-packages\\\\pyspark\\\\examples\\\\src\\\\main\\\\python\\\\ml\\\\__pycache__\\\\multiclass_logistic_regression_with_elastic_net.cpython-310.pyc.2791039050704'\n",
      "      [end of output]\n",
      "  \n",
      "  note: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "error: legacy-install-failure\n",
      "\n",
      "× Encountered error while trying to install package.\n",
      "╰─> pyspark\n",
      "\n",
      "note: This is an issue with the package mentioned above, not pip.\n",
      "hint: See above for output from the failure.\n",
      "\n",
      "[notice] A new release of pip available: 22.3.1 -> 23.0.1\n",
      "[notice] To update, run: C:\\Users\\ADMIN\\AppData\\Local\\Microsoft\\WindowsApps\\PythonSoftwareFoundation.Python.3.10_qbz5n2kfra8p0\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('Praction').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://DESKTOP-G9D9T0F:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.3.2</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Praction</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x17ceff8cca0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.csv('D:\\Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "| _c0|_c1|\n",
      "+----+---+\n",
      "|Name|Age|\n",
      "|   a| 32|\n",
      "|   b| 19|\n",
      "|   c| 27|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pyspark = spark.read.option('header','true').csv('D:\\Book1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+---+\n",
      "|Name|Age|\n",
      "+----+---+\n",
      "|   a| 32|\n",
      "|   b| 19|\n",
      "|   c| 27|\n",
      "+----+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_pyspark.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "47e86e659cc4c7e7c8281f4dfa198d26eba569ed7d4f5779d5419dff2bd0d92c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
